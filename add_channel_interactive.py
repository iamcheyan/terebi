#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
YouTubeé¢‘é“æ·»åŠ å·¥å…· - æ”¯æŒæ‰¹é‡æ·»åŠ 
ç”¨æ³•ï¼š
- äº¤äº’æ¨¡å¼ï¼špython add_channel_interactive.py
- å•ä¸ªé¢‘é“ï¼špython add_channel_interactive.py --url @handle
- æ‰¹é‡æ·»åŠ ï¼špython add_channel_interactive.py --url @handle1 @handle2 @handle3
"""

import argparse
import json
import os
import sys
import urllib.parse
import urllib.request
from datetime import datetime, timezone
from pathlib import Path
from typing import List, Optional, Tuple

# é¡¹ç›®æ ¹ç›®å½•
PROJECT_ROOT = Path(__file__).parent
CONFIG_FILE = PROJECT_ROOT / "japan_tv_youtube_channels.json"
DATA_DIR = PROJECT_ROOT / "data"
IMG_DIR = PROJECT_ROOT / "img"
IMG_RESIZED_DIR = IMG_DIR / "resized"

# å°è¯•å¯¼å…¥ Pillow
try:
    from PIL import Image
    from io import BytesIO
except ImportError:
    Image = None
    BytesIO = None


def load_config() -> dict:
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    if not CONFIG_FILE.exists():
        print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {CONFIG_FILE}")
        sys.exit(1)
    
    with open(CONFIG_FILE, "r", encoding="utf-8") as f:
        return json.load(f)


def save_config(config: dict) -> bool:
    """ä¿å­˜é…ç½®æ–‡ä»¶"""
    try:
        with open(CONFIG_FILE, "w", encoding="utf-8") as f:
            json.dump(config, f, ensure_ascii=False, indent=2)
        return True
    except Exception as e:
        print(f"âŒ ä¿å­˜é…ç½®å¤±è´¥: {e}")
        return False


def load_api_keys() -> List[str]:
    """ä» WEB-INF/config.properties è¯»å– YouTube API Key"""
    config_file = PROJECT_ROOT / "WEB-INF" / "config.properties"
    if not config_file.exists():
        return []
    
    keys = []
    try:
        with open(config_file, "r", encoding="utf-8") as f:
            for line in f:
                line = line.strip()
                if line.startswith("youtube.apikey") and "=" in line:
                    key = line.split("=", 1)[1].strip()
                    if key:
                        keys.append(key)
    except Exception:
        pass
    
    return keys


def normalize_url(url: str) -> str:
    """æ ‡å‡†åŒ–URLæ ¼å¼"""
    if not url:
        return ""
    
    # å¦‚æœåªæ˜¯handleï¼ˆå¦‚ @handleï¼‰ï¼Œè¡¥å……å®Œæ•´URL
    if url.startswith("@"):
        return f"https://www.youtube.com/{url}"
    
    # ç¡®ä¿æ˜¯å®Œæ•´çš„YouTube URL
    if not url.startswith("http"):
        if url.startswith("www.youtube.com"):
            url = "https://" + url
        elif url.startswith("youtube.com"):
            url = "https://www." + url
        else:
            url = "https://www.youtube.com/" + url
    
    return url


def extract_handle_or_id(url: str) -> str:
    """ä»URLæå–handleæˆ–ID"""
    if not url:
        return ""
    
    # å¤„ç† @handle æ ¼å¼
    if "/@" in url:
        return url.split("/@")[-1].split("?")[0].split("/")[0]
    
    # å¤„ç† /channel/UC... æ ¼å¼
    if "/channel/" in url:
        return url.split("/channel/")[-1].split("?")[0].split("/")[0]
    
    # å¤„ç† /c/channel_name æ ¼å¼
    if "/c/" in url:
        return url.split("/c/")[-1].split("?")[0].split("/")[0]
    
    return ""


def check_channel_exists(url: str) -> bool:
    """æ£€æŸ¥é¢‘é“æ˜¯å¦å·²å­˜åœ¨"""
    config = load_config()
    
    for cat_data in config.values():
        if not isinstance(cat_data, dict):
            continue
        for subcat_data in cat_data.values():
            if not isinstance(subcat_data, list):
                continue
            for channel in subcat_data:
                if isinstance(channel, dict) and channel.get("url") == url:
                    return True
    return False


def upsert_channel(url: str, name: str, category: str, subcategory: str) -> bool:
    """æ·»åŠ æˆ–æ›´æ–°é¢‘é“åˆ°é…ç½®"""
    config = load_config()
    
    # æŸ¥æ‰¾ç°æœ‰é¢‘é“
    for cat_data in config.values():
        if not isinstance(cat_data, dict):
            continue
        for subcat_data in cat_data.values():
            if not isinstance(subcat_data, list):
                continue
            for i, channel in enumerate(subcat_data):
                if isinstance(channel, dict) and channel.get("url") == url:
                    # æ›´æ–°ç°æœ‰é¢‘é“
                    subcat_data[i] = {
                        "name": name,
                        "url": url,
                        "bakname": "",
                        "cached": False,
                        "skip": False
                    }
                    print(f"âœ… å·²æ›´æ–°é¢‘é“: {name}")
                    return save_config(config)
    
    # æ·»åŠ æ–°é¢‘é“
    if category not in config:
        config[category] = {}
    if subcategory not in config[category]:
        config[category][subcategory] = []
    
    new_channel = {
        "name": name,
        "url": url,
        "bakname": "",
        "cached": False,
        "skip": False
    }
    
    config[category][subcategory].append(new_channel)
    print(f"âœ… å·²æ·»åŠ é¢‘é“: {name}")
    return save_config(config)


def http_get_json(url: str, params: dict) -> dict:
    """å‘é€HTTP GETè¯·æ±‚å¹¶è¿”å›JSON"""
    if params:
        query = urllib.parse.urlencode(params)
        url = f"{url}?{query}"
    
    try:
        req = urllib.request.Request(url, headers={"User-Agent": "Mozilla/5.0"})
        with urllib.request.urlopen(req, timeout=30) as resp:
            return json.loads(resp.read().decode("utf-8"))
    except Exception as e:
        print(f"âŒ HTTPè¯·æ±‚å¤±è´¥: {e}")
        return {}


def resolve_channel_id(url: str, api_key: str) -> Tuple[Optional[str], Optional[str]]:
    """è§£æé¢‘é“IDå’Œæ ‡é¢˜"""
    handle_or_id = extract_handle_or_id(url)
    if not handle_or_id:
        return None, None
    
    # å°è¯•ä½œä¸ºhandleæŸ¥è¯¢
    if not handle_or_id.startswith("UC"):
        try:
            # è§£ç ç™¾åˆ†å·ç¼–ç 
            decoded_handle = urllib.parse.unquote(handle_or_id)
            resp = http_get_json(
                "https://www.googleapis.com/youtube/v3/channels",
                {
                    "part": "snippet",
                    "forUsername": decoded_handle,
                    "key": api_key
                }
            )
            items = resp.get("items", [])
            if items:
                return items[0]["id"], items[0]["snippet"]["title"]
        except Exception:
            pass
    
    # å°è¯•ä½œä¸ºIDæŸ¥è¯¢
    try:
        resp = http_get_json(
            "https://www.googleapis.com/youtube/v3/channels",
            {
                "part": "snippet",
                "id": handle_or_id,
                "key": api_key
            }
        )
        items = resp.get("items", [])
        if items:
            return items[0]["id"], items[0]["snippet"]["title"]
    except Exception:
        pass
    
    return None, None


def fetch_channel_uploads(channel_id: str, api_key: str, max_count: int = 200) -> List[dict]:
    """è·å–é¢‘é“ä¸Šä¼ çš„è§†é¢‘åˆ—è¡¨"""
    videos = []
    next_page_token = None
    
    while len(videos) < max_count:
        params = {
            "part": "snippet",
            "channelId": channel_id,
            "type": "video",
            "order": "date",
            "maxResults": min(50, max_count - len(videos)),
            "key": api_key
        }
        
        if next_page_token:
            params["pageToken"] = next_page_token
        
        resp = http_get_json("https://www.googleapis.com/youtube/v3/search", params)
        items = resp.get("items", [])
        
        if not items:
            break
        
        for item in items:
            snippet = item.get("snippet", {})
            video = {
                "id": item.get("id", {}).get("videoId", ""),
                "title": snippet.get("title", ""),
                "description": snippet.get("description", ""),
                "publishedAt": snippet.get("publishedAt", ""),
                "thumbnails": snippet.get("thumbnails", {}),
                "url": f"https://www.youtube.com/watch?v={item.get('id', {}).get('videoId', '')}"
            }
            videos.append(video)
        
        next_page_token = resp.get("nextPageToken")
        if not next_page_token:
            break
    
    return videos[:max_count]


def save_data_file(name: str, channel_id: str, channel_title: str, videos: List[dict]) -> Path:
    """ä¿å­˜è§†é¢‘æ•°æ®åˆ°JSONæ–‡ä»¶"""
    DATA_DIR.mkdir(exist_ok=True)
    
    payload = {
        "channel_id": channel_id,
        "channel_name": channel_title or name,
        "updated_at": datetime.now(timezone.utc).isoformat(),
        "videos": videos,
    }
    
    out_path = DATA_DIR / f"{name}.json"
    with open(out_path, "w", encoding="utf-8") as f:
        json.dump(payload, f, ensure_ascii=False, indent=2)
    
    return out_path


def pick_best_thumbnail(snippet: dict) -> Optional[str]:
    """é€‰æ‹©æœ€ä½³ç¼©ç•¥å›¾URL"""
    thumbs = (snippet or {}).get("thumbnails", {})
    for key in ["maxres", "standard", "high", "medium", "default"]:
        url = (thumbs.get(key) or {}).get("url")
        if url:
            return url
    return None


def download_channel_avatar(channel_id: str, api_key: str, save_name: str) -> Tuple[Optional[Path], Optional[Path]]:
    """ä¸‹è½½é¢‘é“å¤´åƒå¹¶ç”Ÿæˆç¼©ç•¥å›¾ï¼Œè¿”å› (åŸå›¾è·¯å¾„, ç¼©ç•¥å›¾è·¯å¾„)"""
    # æ‹‰å–é¢‘é“ä¿¡æ¯ä»¥è·å–ç¼©ç•¥å›¾
    ch = http_get_json(
        "https://www.googleapis.com/youtube/v3/channels",
        {"part": "snippet", "id": channel_id, "key": api_key}
    )
    try:
        snippet = ch.get("items", [])[0]["snippet"]
    except Exception:
        snippet = None
    img_url = pick_best_thumbnail(snippet) if snippet else None
    if not img_url:
        return None, None

    # ä¸‹è½½å›¾ç‰‡
    try:
        req = urllib.request.Request(img_url, headers={"User-Agent": "Mozilla/5.0"})
        with urllib.request.urlopen(req, timeout=20) as resp:
            content = resp.read()
    except Exception:
        return None, None

    IMG_DIR.mkdir(parents=True, exist_ok=True)
    IMG_RESIZED_DIR.mkdir(parents=True, exist_ok=True)
    raw_path = IMG_DIR / f"{save_name}.jpg"
    resized_path = IMG_RESIZED_DIR / f"{save_name}.jpg"

    # ä¿å­˜åŸå›¾
    try:
        with open(raw_path, "wb") as f:
            f.write(content)
    except Exception:
        raw_path = None

    # ç”Ÿæˆç¼©ç•¥å›¾
    try:
        if Image is None:
            return raw_path, None
        with Image.open(BytesIO(content)) as im:
            # è½¬æˆRGBï¼Œç­‰æ¯”ç¼©æ”¾åˆ° 128x128 ç”»å¸ƒå†…ï¼Œå†å±…ä¸­é“ºæ»¡è£å‰ªï¼ˆæ–¹å½¢ï¼‰
            im = im.convert("RGB")
            size = 128
            # å…ˆæŒ‰çŸ­è¾¹ç­‰æ¯”æ”¾å¤§ï¼Œåå±…ä¸­è£å‰ª
            ratio = max(size / im.width, size / im.height)
            new_w, new_h = int(im.width * ratio), int(im.height * ratio)
            im = im.resize((new_w, new_h), Image.LANCZOS)
            left = (new_w - size) // 2
            top = (new_h - size) // 2
            im = im.crop((left, top, left + size, top + size))
            im.save(resized_path, format="JPEG", quality=88, optimize=True)
    except Exception:
        resized_path = None

    return raw_path, resized_path


def process_single_channel(url: str, name: str, category: str, subcategory: str) -> bool:
    """å¤„ç†å•ä¸ªé¢‘é“ï¼šæ·»åŠ åˆ°é…ç½®å¹¶æŠ“å–æ•°æ®"""
    url = normalize_url(url)
    if not url:
        print(f"âŒ URL æ— æ•ˆ: {url}")
        return False

    # é»˜è®¤åç§°ï¼šä»URLæå– handle/IDï¼Œå¹¶å¯¹ç™¾åˆ†å·ç¼–ç è¿›è¡Œè§£ç 
    if not name:
        name = urllib.parse.unquote(extract_handle_or_id(url)).strip()
        if not name:
            print(f"âŒ æ— æ³•ç¡®å®šé¢‘é“åç§°: {url}")
            return False

    print(f"=== å¤„ç†é¢‘é“: {name} ===")
    print(f"URL: {url}")
    print(f"åˆ†ç±»/å­åˆ†ç±»: {category} / {subcategory}")

    # æ£€æŸ¥é¢‘é“æ˜¯å¦å·²å­˜åœ¨
    if check_channel_exists(url):
        print(f"â­ï¸ é¢‘é“å·²å­˜åœ¨ï¼Œè·³è¿‡: {name}")
        return True

    # æ·»åŠ åˆ°é…ç½®
    ok = upsert_channel(url=url, name=name, category=category, subcategory=subcategory)
    if not ok:
        print(f"âŒ æ·»åŠ å¤±è´¥: {name}")
        return False

    print(f"âœ… å·²æ·»åŠ åˆ°é…ç½®: {name}")

    # æŠ“å–è¯¥URLå¯¹åº”é¢‘é“å¹¶ç”Ÿæˆ data/{åç§°}.json
    print("=== æ­£åœ¨è¯»å– API Key å¹¶æŠ“å–è¯¥é¢‘é“ ===")
    keys = load_api_keys()
    if not keys:
        print("âŒ æœªåœ¨ WEB-INF/config.properties ä¸­æ‰¾åˆ° youtube.apikeyï¼Œæ— æ³•æŠ“å–ã€‚ä»…å®Œæˆæ·»åŠ åˆ°é…ç½®ã€‚")
        return True

    # è½®æ¢ API Key è§£æé¢‘é“ID
    ch_id, ch_title = None, None
    api_key = None
    for k in keys:
        api_key = k
        ch_id, ch_title = resolve_channel_id(url, k)
        if ch_id:
            break
    if not ch_id:
        print("âŒ æ— æ³•è§£æé¢‘é“IDï¼ŒæŠ“å–ç»ˆæ­¢ã€‚å·²å®Œæˆæ·»åŠ åˆ°é…ç½®ã€‚")
        return True

    videos = fetch_channel_uploads(ch_id, api_key, max_count=200)
    out_path = save_data_file(name=name, channel_id=ch_id, channel_title=ch_title or name, videos=videos)

    # ä¸‹è½½å¹¶ç”Ÿæˆå¤´åƒç¼©ç•¥å›¾ï¼ˆä¸ä¸­æ–­ä¸»æµç¨‹ï¼‰
    raw_img, resized_img = download_channel_avatar(channel_id=ch_id, api_key=api_key, save_name=name)

    print(f"âœ… æŠ“å–å®Œæˆï¼š{len(videos)} æ¡è§†é¢‘ â†’ {out_path}")
    if raw_img:
        print(f"âœ… å·²ä¸‹è½½å¤´åƒï¼š{raw_img}")
    if resized_img:
        print(f"âœ… å·²ç”Ÿæˆç¼©ç•¥å›¾ï¼š{resized_img}")
    else:
        print("âš ï¸ æœªç”Ÿæˆç¼©ç•¥å›¾ï¼ˆå¯èƒ½æœªå®‰è£… Pillow æˆ–ä¸‹è½½å¤±è´¥ï¼‰")
    
    return True


def main():
    parser = argparse.ArgumentParser(description="æ·»åŠ YouTubeé¢‘é“åˆ°é…ç½®å¹¶æŠ“å–æ•°æ®")
    parser.add_argument("--url", nargs="+", help="YouTubeé¢‘é“URLï¼ˆæ”¯æŒå¤šä¸ªï¼Œå¦‚ --url @handle1 @handle2ï¼‰")
    parser.add_argument("--name", help="æ˜¾ç¤ºåç§°ï¼ˆé»˜è®¤ç”¨ handle/IDï¼‰")
    parser.add_argument("--category", default="ãã®ä»–", help="åˆ†ç±»ï¼ˆé»˜è®¤: ãã®ä»–ï¼‰")
    parser.add_argument("--subcategory", default="ãã®ä»–ãƒãƒ£ãƒ³ãƒãƒ«", help="å­åˆ†ç±»ï¼ˆé»˜è®¤: ãã®ä»–ãƒãƒ£ãƒ³ãƒãƒ«ï¼‰")
    parser.add_argument("--yes", "-y", action="store_true", help="è‡ªåŠ¨ç¡®è®¤ï¼Œä¸è¯¢é—®")
    args = parser.parse_args()

    if args.url:
        # æ‰¹é‡æ·»åŠ æ¨¡å¼
        urls = args.url
        category = args.category
        subcategory = args.subcategory
        
        print(f"=== æ‰¹é‡æ·»åŠ æ¨¡å¼ ===")
        print(f"é¢‘é“æ•°é‡: {len(urls)}")
        print(f"åˆ†ç±»/å­åˆ†ç±»: {category} / {subcategory}")
        print(f"URLåˆ—è¡¨:")
        for i, url in enumerate(urls, 1):
            print(f"  {i}. {url}")
        
        if not args.yes:
            try:
                if input(f"\nç¡®è®¤æ‰¹é‡æ·»åŠ  {len(urls)} ä¸ªé¢‘é“ï¼Ÿ(y/N): ").lower() != 'y':
                    print("å·²å–æ¶ˆ")
                    return
            except EOFError:
                print("âŒ æ— æ³•è¯»å–è¾“å…¥ï¼Œè¯·ä½¿ç”¨ --yes å‚æ•°è‡ªåŠ¨ç¡®è®¤")
                return
        
        success_count = 0
        for i, url in enumerate(urls, 1):
            print(f"\n=== å¤„ç†ç¬¬ {i}/{len(urls)} ä¸ªé¢‘é“ ===")
            try:
                if process_single_channel(url, args.name, category, subcategory):
                    success_count += 1
                    print(f"âœ… ç¬¬ {i} ä¸ªé¢‘é“å¤„ç†å®Œæˆ")
                else:
                    print(f"âŒ ç¬¬ {i} ä¸ªé¢‘é“å¤„ç†å¤±è´¥")
            except Exception as e:
                print(f"âŒ ç¬¬ {i} ä¸ªé¢‘é“å¤„ç†å¤±è´¥: {e}")
                continue
        
        print(f"\n=== æ‰¹é‡å¤„ç†å®Œæˆ ===")
        print(f"æˆåŠŸ: {success_count}/{len(urls)} ä¸ªé¢‘é“")
        if success_count > 0:
            print("ğŸ‘‰ è¯·åˆ·æ–°ç½‘é¡µæŸ¥çœ‹æ–°é¢‘é“")
    else:
        # äº¤äº’æ¨¡å¼
        try:
            url = input("è¯·è¾“å…¥YouTubeé¢‘é“åœ°å€: ").strip()
        except EOFError:
            print("âŒ æœªæä¾›URL")
            sys.exit(1)

        if not url:
            print("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„URL")
            return

        name = args.name
        if not name:
            name = urllib.parse.unquote(extract_handle_or_id(url)).strip()
            if not name:
                print("âŒ æ— æ³•ç¡®å®šé¢‘é“åç§°ï¼Œè¯·ä½¿ç”¨ --name æŒ‡å®š")
                sys.exit(1)

        print("=== é¢„è§ˆ ===")
        print(f"URL: {url}")
        print(f"åç§°: {name}")
        print(f"åˆ†ç±»/å­åˆ†ç±»: {args.category} / {args.subcategory}")

        if input("\nç¡®è®¤æ·»åŠ ï¼Ÿ(y/N): ").lower() != 'y':
            print("å·²å–æ¶ˆ")
            return

        process_single_channel(url, name, args.category, args.subcategory)


if __name__ == "__main__":
    main()